{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b156a7ed-456c-48f7-80c5-a59919eed48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import glob\n",
    "\n",
    "\n",
    "from datetime import datetime, time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "import supermag_api\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from scipy.integrate import trapz\n",
    "\n",
    "from scipy.stats import genextreme, genpareto\n",
    "from pyextremes import get_return_periods\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61a99be-e8f8-4021-963c-25405c7d13ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load regions\n",
    "regions_gdf = gpd.read_file(\"/Users/ryanmc/Documents/Conferences/Jack_Eddy_Symposium_2022/dev/NERC_Reliability_Coordinators.geojson\")\n",
    "# Ensure the CRS is WGS84 (EPSG:4326)\n",
    "if regions_gdf.crs is None or regions_gdf.crs.to_string() != \"EPSG:4326\":\n",
    "    print('converting to EPSG: 4326')\n",
    "    regions_gdf = regions_gdf.to_crs(\"EPSG:4326\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c017cc-f412-4fe6-811d-bdec57067000",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regions_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e02e5ac-7b2a-450b-b4e3-3e14cc56dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in supermag station information \n",
    "df_sm_stations = pd.read_csv('/Users/ryanmc/Documents/Conferences/Jack_Eddy_Symposium_2022/dev/supermag_data/supermag-stations-information-downloadedJuly2025.csv',\n",
    "                            usecols=[0,1,2,3,4,5])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996c259d-37fa-4c24-89fa-fdeea7151878",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sm_stations['GEOLON_alt'] = ((df_sm_stations['GEOLON'] + 180) % 360) - 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718a9f1c-aacd-409b-ace7-48b62e71aa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sm_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74875e0a-98ca-4226-af2b-5208ea0b8619",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_sm_stations = gpd.GeoDataFrame(\n",
    "                            df_sm_stations,\n",
    "                            geometry=[Point(xy) for xy in zip(df_sm_stations[\"GEOLON_alt\"], df_sm_stations[\"GEOLAT\"])],\n",
    "                            crs=\"EPSG:4326\"\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cf9646-ff9c-483a-95c3-be4bb2b4369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_sm_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd665aa1-89be-4256-931b-b6645d6cf1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_stations_locations_with_regions = gpd.sjoin(gdf_sm_stations, regions_gdf, how=\"left\", predicate=\"within\")\n",
    "sm_stations_locations_with_regions['Region'] = sm_stations_locations_with_regions['NAME']\n",
    "sm_stations_locations_with_regions_US = sm_stations_locations_with_regions.dropna(subset=['Region'], inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc0e337-f441-40c3-a9ee-ec17bd6ea6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm_stations_locations_with_regions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db2f1c6-31da-410c-9c49-efae8bc119cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_stations_locations_with_regions_US[sm_stations_locations_with_regions_US['IAGA'] == 'R05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0655557f-e6d6-4c88-973a-94e9b732a7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the GIC sensor locations for May 2024 storm\n",
    "\n",
    "file_sensor_locations = os.path.join('/Users/ryanmc/Documents/Conferences/Jack_Eddy_Symposium_2022/dev/','risk-resiliency-spwx','data','event_20240510','GIC','gic_monitors.csv')\n",
    "\n",
    "df_sensor_locations = pd.read_csv(file_sensor_locations)\n",
    "df_sensor_locations[' Longitude'] = df_sensor_locations[' Longitude'] * -1.\n",
    "\n",
    "# Convert sensor DataFrame to GeoDataFrame\n",
    "gdf_sensor_locations = gpd.GeoDataFrame(\n",
    "                            df_sensor_locations,\n",
    "                            geometry=[Point(xy) for xy in zip(df_sensor_locations[\" Longitude\"], df_sensor_locations[\" Latitude\"])],\n",
    "                            crs=\"EPSG:4326\"\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8a4c87-b14f-4afb-8b31-f9854bdb420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf_sensor_locations[' Longitude'] = gdf_sensor_locations[' Longitude'] * -1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c7f08-f2c3-43bb-9bb7-ea8ecca7ff31",
   "metadata": {},
   "source": [
    "Previous analyses: \n",
    "- Closest sensor to FRD SuperMAG station: 10427\n",
    "- Closest sensor to R07 SuperMAG station: 10297\n",
    "- Closest sensor to FRN SuperMAG station: 10418 (informed by Bhagyashree to replace 10448)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbc3475-bba6-4cf8-bfc2-7a5623959d13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdf_sensor_locations#[gdf_sensor_locations['Device ID']==10427]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ae6df8-8547-42bb-8051-9608a5f046ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sm_stations_locations_with_regions_US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699af11a-1be1-421e-9411-40f3463dfd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_stations_locations_with_regions_US[sm_stations_locations_with_regions_US['IAGA']==target_station]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb0737a-9a38-4f5f-b661-9ae43e344581",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example: your dataframe of sensors\n",
    "# Assume df has columns: ['sensor_id', 'latitude', 'longitude']\n",
    "# And your target location:\n",
    "target_station = 'FRN'\n",
    "glat_mag = sm_stations_locations_with_regions_US[sm_stations_locations_with_regions_US['IAGA']==target_station]['GEOLAT']\n",
    "glon_mag = sm_stations_locations_with_regions_US[sm_stations_locations_with_regions_US['IAGA']==target_station]['GEOLON']\n",
    "target_lat = glat_mag.values[0]     # example latitude\n",
    "target_lon = glon_mag.values[0]   # example longitude\n",
    "print('target lat,long = ({},{})'.format(target_lat,target_lon))\n",
    "\n",
    "# Convert degrees to radians\n",
    "lat_rad = np.radians(gdf_sensor_locations[' Latitude'])\n",
    "lon_rad = np.radians(gdf_sensor_locations[' Longitude'])\n",
    "target_lat_rad = np.radians(target_lat)\n",
    "target_lon_rad = np.radians(target_lon)\n",
    "\n",
    "# Haversine formula\n",
    "dlat = lat_rad - target_lat_rad\n",
    "dlon = lon_rad - target_lon_rad\n",
    "\n",
    "a = np.sin(dlat / 2)**2 + np.cos(lat_rad) * np.cos(target_lat_rad) * np.sin(dlon / 2)**2\n",
    "c = 2 * np.arcsin(np.sqrt(a))\n",
    "R = 6371  # Earth radius in kilometers\n",
    "distances_km = R * c\n",
    "\n",
    "# Add distances to DataFrame\n",
    "gdf_sensor_locations['distance_km'] = distances_km\n",
    "\n",
    "# Get the top 10 closest sensors\n",
    "closest = gdf_sensor_locations.nsmallest(10, 'distance_km')\n",
    "\n",
    "print(closest[['Device ID', ' Latitude', ' Longitude', 'distance_km']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cf68b4-7fea-42ce-8232-e7d649a6ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest['Device ID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7de6f2-dd5b-498f-a95f-7df6435f5a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data for this event\n",
    "fig, ax = plt.subplots(1, 1, figsize=(22, 16))\n",
    "\n",
    "# Select the stations of interest\n",
    "highlight_stations = sm_stations_locations_with_regions_US[\n",
    "    # sm_stations_locations_with_regions_US['IAGA'].isin(['R02', 'R05','R07', 'FRD', 'FRN'])\n",
    "    sm_stations_locations_with_regions_US['IAGA'].isin(['R07', 'FRD', 'FRN'])\n",
    "]\n",
    "highlight_sensors = gdf_sensor_locations[\n",
    "    gdf_sensor_locations['Device ID'].isin([10427,10418,10297])\n",
    "]\n",
    "\n",
    "# Plot the NERC RC regions colored by region name or code\n",
    "regions_gdf.plot(column='NAME', categorical=True, legend=True, \n",
    "        edgecolor='black', linewidth=0.5, ax=ax, alpha=0.5)\n",
    "\n",
    "# Plot sensor locations\n",
    "sm_stations_locations_with_regions_US.plot(ax=ax, marker='x',color='blue', markersize=30, label='Magnetometers')\n",
    "gdf_sensor_locations.plot(ax=ax, color='red', markersize=30, label='Sensors')\n",
    "\n",
    "# Plot highlighted stations with bigger markers\n",
    "highlight_stations.plot(ax=ax, color='yellow', edgecolor='black', markersize=200, marker='*', label='Highlighted Stations')\n",
    "\n",
    "# Add text labels so they’re clearly indicated\n",
    "for x, y, label in zip(highlight_stations.geometry.x, highlight_stations.geometry.y, highlight_stations['IAGA']):\n",
    "    ax.text(x + 0.5, y + 0.5, label, fontsize=20, fontweight='bold', color='black')\n",
    "\n",
    "# Plot highlighted sensors with bigger markers\n",
    "highlight_sensors.plot(ax=ax, color='green', edgecolor='black', markersize=200, marker='*', label='Highlighted Sensors')\n",
    "\n",
    "# Add text labels so they’re clearly indicated\n",
    "for x, y, label in zip(highlight_sensors.geometry.x, highlight_sensors.geometry.y, highlight_sensors['Device ID']):\n",
    "    if label == 10427:\n",
    "        ax.text(x + 0.5, y + 0.5, label, fontsize=20, fontweight='bold', color='black')\n",
    "    else:\n",
    "        ax.text(x - 1.5, y - 1.5, label, fontsize=20, fontweight='bold', color='black')\n",
    "\n",
    "ax.set_title('NERC Reliability Coordinator Regions with GIC sensors and SuperMAG magnetometers', fontsize=24)\n",
    "ax.set_axis_off()\n",
    "# ax.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b88235-6258-479e-b67a-624c572e40d5",
   "metadata": {},
   "source": [
    "TODO: look at 10448 -> move to 10418"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc1ff77-0ba8-4da9-9517-fd858e66e9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_stations_region = {}\n",
    "\n",
    "grouped = sm_stations_locations_with_regions_US.groupby('Region')\n",
    "for region, region_data in grouped:\n",
    "    sm_stations_region[region] = [region_data['IAGA'],region_data['GEOLON_alt'],region_data['GEOLAT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63731f24-c036-4c53-9f5e-fd0061a2a3d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sm_stations_region['MIDCONTINENT INDEPENDENT SYSTEM OPERATOR, INC..']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe97276-5185-4553-adde-fa3af15aa1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(2013,2025)\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fc0798-6691-46d5-b12d-0938d004791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime(years[0],6,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa649d13-ca4b-430d-b879-56489415753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(status,stations) = supermag_api.SuperMAGGetInventory(supermag_userid,\n",
    "                                                          datetime(years[0],1,1),\n",
    "                                                         86400*365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c20a7b-d55f-42e7-8062-1459a8901c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "supermag_userid = 'rymc1012'\n",
    "flags = 'geo'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca35121c-b4b3-46d6-88af-d00e02013d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (status,sm_data)=supermag_api.SuperMAGGetData(supermag_userid,\n",
    "#                                      datetime(years[0],1,1),\n",
    "#                                      86400*365,\n",
    "#                                      flags,'FRN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39130cb3-cd3e-474b-ac61-e62dad96e608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloaded 2024 data for FRD, FRN, and R05\n",
    "file_FRD = '/Users/ryanmc/Documents/Conferences/Jack_Eddy_Symposium_2022/dev/supermag_data/SuperMAG_60s_FRD_2024_rev-0006.1753287357.netcdf'\n",
    "# ds = xr.open_dataset(file_FRD)\n",
    "ds = xr.open_dataset(file_FRD, chunks={'time': 10000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e8c52b-1167-4dd7-b31f-41e1b2093226",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in ['time_yr', 'time_mo', 'time_dy', 'time_hr', 'time_mt', 'time_sc']:\n",
    "    ds[var] = ds[var].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4e22ff-06d3-45f4-a13f-526611bc6e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.drop_vars(['extent','dbe_geo','dbn_geo','dbn_geo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163621cb-892d-4b01-a4ab-2a1aeb2e16fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92420bda-0275-4fc1-ac06-6400086c766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_datetime_vec(y, mo, d, h, mi, s):\n",
    "    y = y.astype(str)\n",
    "    mo = np.char.zfill(mo.astype(str), 2)\n",
    "    d = np.char.zfill(d.astype(str), 2)\n",
    "    h = np.char.zfill(h.astype(str), 2)\n",
    "    mi = np.char.zfill(mi.astype(str), 2)\n",
    "    s = np.char.zfill(s.astype(str), 2)\n",
    "    \n",
    "    dt_str = np.char.add(y, '-')\n",
    "    dt_str = np.char.add(dt_str, mo)\n",
    "    dt_str = np.char.add(dt_str, '-')\n",
    "    dt_str = np.char.add(dt_str, d)\n",
    "    dt_str = np.char.add(dt_str, 'T')\n",
    "    dt_str = np.char.add(dt_str, h)\n",
    "    dt_str = np.char.add(dt_str, ':')\n",
    "    dt_str = np.char.add(dt_str, mi)\n",
    "    dt_str = np.char.add(dt_str, ':')\n",
    "    dt_str = np.char.add(dt_str, s)\n",
    "    \n",
    "    return dt_str.astype('datetime64[ns]')\n",
    "\n",
    "\n",
    "datetime_da = xr.apply_ufunc(\n",
    "    build_datetime_vec,\n",
    "    ds['time_yr'], ds['time_mo'], ds['time_dy'],\n",
    "    ds['time_hr'], ds['time_mt'], ds['time_sc'],\n",
    "    dask='allowed',\n",
    "    output_dtypes=[np.dtype('datetime64[ns]')]\n",
    ")\n",
    "\n",
    "\n",
    "# Assign as time coordinate\n",
    "ds = ds.assign_coords(time=datetime_da)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5111b6bc-212f-4939-a0cb-71e7cc0f9dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = ds.assign_coords(time=pd.to_datetime(datetime_da.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce582d3-cd83-4d29-886b-0def05e9a254",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['time'] = pd.to_datetime(ds['time'].values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf89d3c-2e5c-4ac2-b3ce-c3d29d8232d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = np.sqrt(ds['dbe_nez']**2 + ds['dbn_nez']**2)\n",
    "ds['H'] = H\n",
    "\n",
    "ds['H'] = ds['H'].rename({'block': 'time'})\n",
    "H_1d = ds['H'].squeeze('vector')  # dims: ('time',)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fe2cac-1877-46b5-8681-47b87b94fe04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08272271-3c5e-4c75-9419-c820253e2381",
   "metadata": {},
   "outputs": [],
   "source": [
    "dH = ds['H'].diff('time')\n",
    "dt = ds['time'].diff('time') / np.timedelta64(1, 's')\n",
    "dt = dt.astype('float64')  # ensure float for safe division\n",
    "\n",
    "\n",
    "dH_dt = dH / dt\n",
    "dH_dt = dH_dt.pad(time=(1, 0), constant_values=np.nan)  # align dimensions\n",
    "ds['dH_dt'] = dH_dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205db85e-f974-4a8f-9d4c-658124f8af76",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['dbe_nez'].dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61232f0b-bb12-4c5e-a95e-99da0564e671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to explicitly define the 'block' dimension to be the 'time'dimension for .diff() to work correctly\n",
    "\n",
    "# ds['dbe_nez'] = ds['dbe_nez'].assign_coords(block=ds['time'])\n",
    "# ds['dbn_nez'] = ds['dbn_nez'].assign_coords(block=ds['time'])\n",
    "# ds = ds.rename_dims({'block': 'time'})  # rename dimension so it's usable\n",
    "ds = ds.rename({'block': 'time'})       # rename coordinate to match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7069e6ce-7925-4db0-bbcf-1b5c03fa1250",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['dbe_nez'].dims\n",
    "#should be (time, vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa44bbf-d32f-4a3a-b1a1-605c7d8a6ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the variation that MacManus found best related to GIC H: the first difference (E_t-E_(t-1) or N_t-N(t-1)) in the two horizontal directions and ,\n",
    "#    https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2025SW004404\n",
    "dbe_dt = ds['dbe_nez'].diff('time')\n",
    "dbn_dt = ds['dbn_nez'].diff('time')\n",
    "\n",
    "# Combine\n",
    "mag_dH_dt = np.sqrt(dbe_dt**2 + dbn_dt**2)\n",
    "\n",
    "# Pad to match original time length\n",
    "mag_dH_dt = mag_dH_dt.pad(time=(1, 0), constant_values=np.nan)\n",
    "\n",
    "# Rebuild DataArray with proper coordinates\n",
    "mag_dH_dt = xr.DataArray(\n",
    "    data=mag_dH_dt.data,\n",
    "    dims=['time', 'vector'],\n",
    "    coords={\n",
    "        'time': ds['time'],\n",
    "        'vector': ds['vector'] if 'vector' in ds.coords else [0]  # dummy if missing\n",
    "    },\n",
    "    name='mag_db_dt'\n",
    ")\n",
    "\n",
    "# Assign to dataset\n",
    "ds['mag_db_dt'] = mag_dH_dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fde159e-e309-4b69-b939-babcc4d4a634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c46ef04-5975-4a65-8e60-b977c91be1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706bfeb3-6f7f-4069-ac64-68d13b3ccbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ds['mag_db_dt'] = ds['mag_db_dt'].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd538491-8f7d-4763-836e-73e0f2792b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['mag_db_dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9207b8e-36f0-4f8c-8a56-660d782103cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['dH_dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83525031-24ff-46d1-bbd0-2387babe5c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227b7904-7646-4af0-beac-f934ed0ffb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Subset dataframe (already done)\n",
    "# df_subset = ds[['H', 'dH_dt']].isel(time=slice(0, 10000)).to_dataframe().reset_index()\n",
    "df_subset = ds[['H', 'mag_db_dt']].isel(time=slice(0, 10000)).to_dataframe().reset_index()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add H trace (left y-axis)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_subset['time'],\n",
    "    y=df_subset['H'],\n",
    "    name='H (nT)',\n",
    "    line=dict(color='blue'),\n",
    "    yaxis='y1'\n",
    "))\n",
    "\n",
    "# # Add dH/dt trace (right y-axis)\n",
    "# fig.add_trace(go.Scatter(\n",
    "#     x=df_subset['time'],\n",
    "#     y=df_subset['dH_dt'],\n",
    "#     name='dH/dt (nT/min)',\n",
    "#     line=dict(color='red'),\n",
    "#     yaxis='y2'\n",
    "# ))\n",
    "\n",
    "# Add mag of the time rate of change of the horizontal magn field to left y-axis\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_subset['time'],\n",
    "    y=df_subset['mag_db_dt'],  # Example: some transformation or different variable\n",
    "    name='time rate of change (nT/min)',\n",
    "    line=dict(color='green', dash='dash'),\n",
    "    yaxis='y2'\n",
    "))\n",
    "\n",
    "\n",
    "# Create axis objects\n",
    "fig.update_layout(\n",
    "    title='H, dH/dt, and magn(time rate of change) (First X points)',\n",
    "    xaxis=dict(title='Time'),\n",
    "    yaxis=dict(\n",
    "        title='H (nT)',\n",
    "        titlefont=dict(color='blue'),\n",
    "        tickfont=dict(color='blue'),\n",
    "        side='left'\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title='dH/dt (nT/min) or magn(db/dt)',\n",
    "        titlefont=dict(color='red'),\n",
    "        tickfont=dict(color='red'),\n",
    "        overlaying='y',\n",
    "        side='right'\n",
    "    ),\n",
    "    height=600,\n",
    "    legend=dict(x=0.1, y=1.1, orientation='h')\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ea7725-5428-4f8a-88ce-f56b9d050cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['dbe_nez'].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab4104-e1c1-4412-b4d1-a75c1271417b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dbe_dt.compute()\n",
    "# dbn_dt.compute()\n",
    "dbe_dt.values[0:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5ffb97-ec22-466c-b81b-40018709f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Subset dataframe (already done)\n",
    "plt.plot(ds['time'].values[0:1000],ds['dbe_nez'].values[0:1000],color='b')\n",
    "plt.plot(ds['time'].values[0:1000],ds['dbn_nez'].values[0:1000],color='r')\n",
    "plt.plot(ds['time'].values[0:1000],dbe_dt.values[0:1000],'b--')\n",
    "plt.plot(ds['time'].values[0:1000],dbn_dt.values[0:1000],'r--')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05fb405-9a03-44ee-8385-5c14dcd1ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_max_H = H_da.resample(time='D').max()\n",
    "# block_max_dHdt = dHdt_da.resample(time='D').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eba3f5-b4f3-4fbd-885f-07fa518ec752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H_da = xr.DataArray(ds['H'].data, dims=['time'], coords={'time': ds.coords['time']})\n",
    "# dHdt_da = xr.DataArray(ds['dH_dt'].data, dims=['time'], coords={'time': ds.coords['time']})\n",
    "\n",
    "# block_max_H = H_da.resample(time='D').max()\n",
    "# block_max_dHdt = dHdt_da.resample(time='D').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd531a7c-4ad8-4da9-8ea4-21398e093a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVA \n",
    "\n",
    "\n",
    "# # Resample to monthly block maxima\n",
    "# block_max_H = ds['H'].resample(time='M').max()\n",
    "# block_max_dHdt = ds['dH_dt'].resample(time='M').max()\n",
    "\n",
    "# Resample to daily block maxima\n",
    "block_max_H = ds['H'].resample(time='D').max()\n",
    "block_max_dHdt = ds['dH_dt'].resample(time='D').max()\n",
    "block_max_magdbdt = ds['mag_db_dt'].resample(time='D').max()\n",
    "\n",
    "\n",
    "# Drop NaNs\n",
    "block_H = block_max_H.values\n",
    "block_H = block_H[np.isfinite(block_H)]\n",
    "\n",
    "# Fit GEV\n",
    "shape_H, loc_H, scale_H = genextreme.fit(block_H)\n",
    "\n",
    "\n",
    "# Drop NaNs\n",
    "block_magdbdt = block_max_magdbdt.values\n",
    "block_magdbdt = block_magdbdt[np.isfinite(block_magdbdt)]\n",
    "\n",
    "# Fit GEV\n",
    "shape_magdbdt, loc_magdbdt, scale_magdbdt = genextreme.fit(block_magdbdt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a0ed52-a4fa-4166-8c2e-e729ee26dd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute theoretical quantiles\n",
    "percs = np.linspace(0, 100, len(block_H))\n",
    "q_empirical = np.percentile(block_H, percs)\n",
    "q_theoretical = genextreme.ppf(percs / 100, shape_H, loc=loc_H, scale=scale_H)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(q_theoretical, q_empirical, c='blue', label='Data')\n",
    "plt.plot(q_theoretical, q_theoretical, 'r--', label='1:1 Line')\n",
    "plt.xlabel('Theoretical Quantiles (GEV)')\n",
    "plt.ylabel('Empirical Quantiles (Data)')\n",
    "plt.title('Q-Q Plot for H Block Maxima (GEV Fit)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Compute theoretical quantiles\n",
    "percs = np.linspace(0, 100, len(block_magdbdt))\n",
    "q_empirical = np.percentile(block_magdbdt, percs)\n",
    "q_theoretical = genextreme.ppf(percs / 100, shape_magdbdt, loc=loc_magdbdt, scale=scale_magdbdt)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(q_theoretical, q_empirical, c='blue', label='Data')\n",
    "plt.plot(q_theoretical, q_theoretical, 'r--', label='1:1 Line')\n",
    "plt.xlabel('Theoretical Quantiles (GEV)')\n",
    "plt.ylabel('Empirical Quantiles (Data)')\n",
    "plt.title('Q-Q Plot for mag(db/dt) Block Maxima (GEV Fit)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709ffc51-2247-4e80-af6e-7bf11cf6c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return Level Plot\n",
    "return_periods = np.linspace(1, 100, 100)\n",
    "p = 1 - 1 / (return_periods * 365.25)\n",
    "return_levels_H = genextreme.ppf(p, shape_H, loc=loc_H, scale=scale_H)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(return_periods, return_levels_H, marker='o')\n",
    "plt.xlabel('Return Period (Years)')\n",
    "plt.ylabel('Return Level of H (nT)')\n",
    "plt.title('Return Level Plot for H Daily Maxima')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Return Level Plot\n",
    "return_periods = np.linspace(1, 100, 100)\n",
    "p = 1 - 1 / (return_periods * 365.25)\n",
    "return_levels_magdbdt = genextreme.ppf(p, shape_magdbdt, loc=loc_magdbdt, scale=scale_magdbdt)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(return_periods, return_levels_magdbdt, marker='o')\n",
    "plt.xlabel('Return Period (Years)')\n",
    "plt.ylabel('Return Level of mag(db/dt) (nT)')\n",
    "plt.title('Return Level Plot for mag(db/dt) Daily Maxima')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc71fd2-ba13-457b-b320-7111a02412d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1260f4c2-514b-4d96-85c1-c3560bdc3e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d71223-f6db-4518-8465-e7cf2f82afaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# developing the capability to identify the closest GIC sensor to the given magnetometer\n",
    "\n",
    "# choose, for now, the Gannon storm \n",
    "gic_sensors_locations_file = '/Users/ryanmc/Documents/Conferences/Jack_Eddy_Symposium_2022/dev/risk-resiliency-spwx/data/event_20240510/GIC/gic_monitors.csv'\n",
    "\n",
    "df_gic_sensors = pd.read_csv(gic_sensors_locations_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86259d4-08a9-402a-8677-90a105abe3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gic_sensors[' Longitude'] = df_gic_sensors[' Longitude'] * -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77bd5d3-4db2-4e37-837f-465286dd9e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example: your dataframe of sensors\n",
    "# Assume df has columns: ['sensor_id', 'latitude', 'longitude']\n",
    "# And your target location:\n",
    "glat_mag = ds['glat'].values[0]\n",
    "glon_mag = ds['glon'].values[0]\n",
    "target_lat = glat_mag[0]     # example latitude\n",
    "target_lon = glon_mag[0]   # example longitude\n",
    "print('target lat,long = ({},{})'.format(target_lat,target_lon))\n",
    "\n",
    "# Convert degrees to radians\n",
    "lat_rad = np.radians(df_gic_sensors[' Latitude'])\n",
    "lon_rad = np.radians(df_gic_sensors[' Longitude'])\n",
    "target_lat_rad = np.radians(target_lat)\n",
    "target_lon_rad = np.radians(target_lon)\n",
    "\n",
    "# Haversine formula\n",
    "dlat = lat_rad - target_lat_rad\n",
    "dlon = lon_rad - target_lon_rad\n",
    "\n",
    "a = np.sin(dlat / 2)**2 + np.cos(lat_rad) * np.cos(target_lat_rad) * np.sin(dlon / 2)**2\n",
    "c = 2 * np.arcsin(np.sqrt(a))\n",
    "R = 6371  # Earth radius in kilometers\n",
    "distances_km = R * c\n",
    "\n",
    "# Add distances to DataFrame\n",
    "df_gic_sensors['distance_km'] = distances_km\n",
    "\n",
    "# Get the top 10 closest sensors\n",
    "closest = df_gic_sensors.nsmallest(10, 'distance_km')\n",
    "\n",
    "print(closest[['Device ID', ' Latitude', ' Longitude', 'distance_km']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021c0a52-a341-4cde-b16e-b319f59d1141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5f18b6-3788-4301-88d4-b8f691625ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get top 10 closest\n",
    "df_gic_sensors['is_closest'] = False\n",
    "df_gic_sensors.loc[df_gic_sensors.nsmallest(10, 'distance_km').index, 'is_closest'] = True\n",
    "\n",
    "# Add the target location\n",
    "df_target = pd.DataFrame({\n",
    "    'Device ID': ['Target'],\n",
    "    ' Latitude': [target_lat],\n",
    "    ' Longitude': [target_lon],\n",
    "    'distance_km': [0],\n",
    "    'is_closest': [True]\n",
    "})\n",
    "\n",
    "df_plot = pd.concat([df_gic_sensors, df_target], ignore_index=True)\n",
    "\n",
    "# Plot with Plotly\n",
    "fig = px.scatter_geo(df_plot,\n",
    "    lat=' Latitude',\n",
    "    lon=' Longitude',\n",
    "    hover_name='Device ID',\n",
    "    color='is_closest',\n",
    "    symbol='is_closest',\n",
    "    scope='usa',\n",
    "    color_discrete_map={True: 'red', False: 'blue'},\n",
    "    title='Sensor Locations and Closest Sensors to Target',\n",
    "    height=600\n",
    ")\n",
    "fig.update_traces(marker=dict(size=8))\n",
    "fig.show()\n",
    "\n",
    "print('note that for these sensors, five of them are essentially in the same location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb2ee89-5adb-43c9-a992-517ece03b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the GIC data for these close sensors \n",
    "\n",
    "file_gic_data = '/Users/ryanmc/Documents/Conferences/Jack_Eddy_Symposium_2022/dev/integrated_data/integrated_data_event_20240510.csv'\n",
    "df_gic_data = pd.read_csv(file_gic_data,index_col=False)\n",
    "if 'Unnamed: 0' in df_gic_data.columns:\n",
    "    df_gic_data = df_gic_data.drop(columns='Unnamed: 0')\n",
    "\n",
    "# Drop unwanted columns, but save IMF and AE index columns\n",
    "cols_to_drop_loc = df_gic_data.columns.get_loc('AE_INDEX')\n",
    "df_gic_data.columns.to_list()[cols_to_drop_loc:]\n",
    "df_gic_data = df_gic_data.drop(df_gic_data.columns.to_list()[cols_to_drop_loc:],axis = 1)\n",
    "\n",
    "df_gic_data['datetimes'] = pd.to_datetime(df_gic_data['datetimes'])\n",
    "df_gic_data = df_gic_data.set_index('datetimes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f8c06d-084a-46b6-9145-e1cd4ff9a4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_selected_data = ds.sel(time=slice('2024-05-10','2024-05-11'))\n",
    "mag_db_dt = mag_selected_data['mag_db_dt']\n",
    "mag_db_dt_df = mag_db_dt.squeeze('vector').to_dataframe(name='mag_db_dt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f625c286-7486-4f96-84cf-9cc1cf13a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_db_dt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705f93d2-35e1-43e2-baf6-81e63ffade0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's say:\n",
    "# df_values: DataFrame with sensor data (columns = sensor IDs)\n",
    "# mag_db_dt: Series with same time index\n",
    "# nearest_ids: list of sensor IDs (subset of df_values.columns)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "nearest_ids = closest['Device ID'].values\n",
    "# Add each nearest sensor trace on y-axis 1\n",
    "for sensor_id in nearest_ids:\n",
    "    try:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_gic_data.index,\n",
    "            y=df_gic_data[str(sensor_id)],\n",
    "            name=f'Sensor {sensor_id}',\n",
    "            yaxis='y1',\n",
    "            mode='lines'\n",
    "        ))\n",
    "    except Exception as e:\n",
    "        print('catching exception {}, advancing...'.format(e))\n",
    "        \n",
    "\n",
    "# Add mag_db_dt on y-axis 2\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=mag_db_dt_df.index,\n",
    "    y=mag_db_dt_df['mag_db_dt'],\n",
    "    name='mag_db_dt',\n",
    "    yaxis='y2',\n",
    "    mode='lines',\n",
    "    line=dict(color='black', width=2, dash='dash')\n",
    "))\n",
    "\n",
    "# Layout with dual axes\n",
    "fig.update_layout(\n",
    "    title='Sensor Values and mag_db_dt',\n",
    "    xaxis=dict(title='Time'),\n",
    "    yaxis=dict(title='Sensor Values', side='left'),\n",
    "    yaxis2=dict(title='mag_db_dt (nT/s)', overlaying='y', side='right'),\n",
    "    legend=dict(x=0.01, y=0.99),\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b16b27-d18c-425f-ac6b-ae9c087331b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's say:\n",
    "# df_values: DataFrame with sensor data (columns = sensor IDs)\n",
    "# mag_db_dt: Series with same time index\n",
    "# nearest_ids: list of sensor IDs (subset of df_values.columns)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "nearest_ids = closest['Device ID'].values\n",
    "# Add each nearest sensor trace on y-axis 1\n",
    "for sensor_id in nearest_ids:\n",
    "    try:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_gic_data.index,\n",
    "            y=abs(df_gic_data[str(sensor_id)].diff()),\n",
    "            name=f'abs(dt(Sensor {sensor_id}))',\n",
    "            yaxis='y1',\n",
    "            mode='lines'\n",
    "        ))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_gic_data.index,\n",
    "            y=abs(df_gic_data[str(sensor_id)]),\n",
    "            name=f'abs(Sensor {sensor_id})',\n",
    "            yaxis='y1',\n",
    "            mode='lines'\n",
    "        ))\n",
    "    except Exception as e:\n",
    "        print('catching exception {}, advancing...'.format(e))\n",
    "        \n",
    "\n",
    "# Add mag_db_dt on y-axis 2\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=mag_db_dt_df.index,\n",
    "    y=mag_db_dt_df['mag_db_dt'],\n",
    "    name='mag_db_dt',\n",
    "    yaxis='y2',\n",
    "    mode='lines',\n",
    "    line=dict(color='black', width=2, dash='dash')\n",
    "))\n",
    "\n",
    "# Layout with dual axes\n",
    "fig.update_layout(\n",
    "    title='abs(time diff of Sensor Values) and mag_db_dt',\n",
    "    xaxis=dict(title='Time'),\n",
    "    yaxis=dict(title='abs( (time diff of) Sensor Values)', side='left'),\n",
    "    yaxis2=dict(title='mag_db_dt (nT/s)', overlaying='y', side='right'),\n",
    "    legend=dict(x=0.01, y=0.99),\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fedb708-b708-4307-aacf-ec46a85ded28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVA for GIC sensors that are close\n",
    "nearest_ids = closest['Device ID'].values\n",
    "\n",
    "    \n",
    "# Load integrated data files\n",
    "integrated_data_directory = '/Users/ryanmc/Documents/Conferences/Jack_Eddy_Symposium_2022/dev/integrated_data/'\n",
    "files = glob.glob( os.path.join(integrated_data_directory,'*.csv') )\n",
    "\n",
    "# Histogram initializations\n",
    "    # Define the histogram bins between 0 and 100\n",
    "bins = np.linspace(0, 100, num=101)  # 101 edges for 100 bins\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2  # Calculate bin centers for plotting later\n",
    "\n",
    "    # Initialize an empty dictionary to store histograms for each region\n",
    "year_data = {}\n",
    "sensors_location_data = {}\n",
    "histogram_data = {}\n",
    "extreme_value_data = {}\n",
    "\n",
    "for f in files:\n",
    "\n",
    "    # read in the numerical data for the sensors in this event\n",
    "    df_tmp = pd.read_csv(f,index_col=False)\n",
    "    if 'Unnamed: 0' in df_tmp.columns:\n",
    "        df_tmp = df_tmp.drop(columns='Unnamed: 0')\n",
    "\n",
    "    # read in the lat-long values for the sensors in this event\n",
    "    print('\\n\\n\\n\\n----------------------------\\nworking on event: {}'.format(f[97:-4])) #f.find('event')\n",
    "    print('\\t--->{}'.format(f))\n",
    "    file_sensor_locations = os.path.join('/Users/ryanmc/Documents/Conferences/Jack_Eddy_Symposium_2022/dev/','risk-resiliency-spwx','data',f[97:-4],'GIC','gic_monitors.csv')\n",
    "\n",
    "    print('\\t--->{}'.format(file_sensor_locations))\n",
    "    df_sensor_locations_tmp = pd.read_csv(file_sensor_locations)\n",
    "    df_sensor_locations_tmp[' Longitude'] = df_sensor_locations_tmp[' Longitude'] * -1.\n",
    "    \n",
    "    # Drop unwanted columns\n",
    "    cols_to_drop_loc = df_tmp.columns.get_loc('AE_INDEX')\n",
    "    df_tmp = df_tmp.drop(df_tmp.columns.to_list()[cols_to_drop_loc:],axis = 1)\n",
    "\n",
    "    # Loop through close sensors\n",
    "    for sensor_id in nearest_ids:\n",
    "\n",
    "        # Initialize histogram for this region if not already present\n",
    "        if sensor_id not in histogram_data:\n",
    "            year_data[sensor_id] = []\n",
    "            histogram_data[sensor_id] = np.zeros(len(bins) - 1)\n",
    "            extreme_value_data[sensor_id] = []#np.array(())\n",
    "\n",
    "        year_data[sensor_id].append(int(f[103:-8]))\n",
    "        try:\n",
    "            device_data = df_tmp[str(sensor_id)]\n",
    "        except:\n",
    "            print('missing device ID = {}, continuing...'.format(sensor_id))\n",
    "            continue\n",
    "\n",
    "\n",
    "        counts, _ = np.histogram(device_data.values, bins=bins)\n",
    "        max_val_device = np.nanmax( abs(device_data.values) )\n",
    "        \n",
    "        # Add these counts to the region's histogram\n",
    "        histogram_data[sensor_id] += counts\n",
    "        extreme_value_data[sensor_id].append(max_val_device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32be29b-6ef7-4d2f-838b-e35f2414a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in nearest_ids: \n",
    "    print('\\n--------------------\\nData details for: {}'.format(s))\n",
    "\n",
    "    print('\\t Years in the data: {} (and number: {})'.format(set(year_data[s]), len(set(year_data[s])) ))\n",
    "    print('\\t Extreme values: {}'.format( np.sort(extreme_value_data[s]) ))\n",
    "    \n",
    "\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f044f2a5-2e92-4691-8833-23922bffe04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a region and do full PHA\n",
    "\n",
    "extreme_value_fits = {}\n",
    "\n",
    "\n",
    "# Step One: plot histogram\n",
    "key = 10427\n",
    "data_pha = histogram_data[key]\n",
    "# data_eva = extreme_value_data[key]\n",
    "\n",
    "# Convert data to a Pandas DataFrame for use with Plotly\n",
    "df_pha = pd.DataFrame({key: data_pha})\n",
    "\n",
    "# Create a histogram using Plotly Express\n",
    "fig = px.bar(\n",
    "        df_pha,\n",
    "        x=bin_centers, \n",
    "        y=data_pha,\n",
    "        title=key,\n",
    "        template=\"plotly_white\",\n",
    "        labels={\"GIC values\", \"Frequency\"},\n",
    "        opacity=0.5  # 50% transparent bars\n",
    "    )\n",
    "\n",
    "# Customize the layout for publication quality\n",
    "fig.update_layout(\n",
    "    title=dict(font=dict(size=18, family=\"Arial\"), x=0.5),\n",
    "    xaxis=dict(title=dict(font=dict(size=14)), tickangle=45),\n",
    "    yaxis=dict(title=dict(font=dict(size=14))),\n",
    "    font=dict(size=12, family=\"Arial\"),\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "# fig.update_yaxes(type=\"log\")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n",
    "\n",
    "# Step two: fit a GEV distribution\n",
    "\n",
    "plt.figure(figsize=(8, 6), dpi=300)\n",
    "for sensor_eva, e in extreme_value_data.items():\n",
    "\n",
    "    if sensor_eva == key:\n",
    "        gev_params = genextreme.fit(e)\n",
    "        \n",
    "        # Extract GEV parameters\n",
    "        shape, loc, scale = gev_params\n",
    "        print(f\"GEV Parameters for sensor_eva {sensor_eva}:\\nShape: {shape}, Location: {loc}, Scale: {scale}\")\n",
    "        extreme_value_fits[sensor_eva] = [shape,loc,scale]\n",
    "        \n",
    "        # Generate x values for plotting\n",
    "        x = np.linspace(min(e), max(e), 100)\n",
    "        \n",
    "        # Compute the PDF of the fitted GEV distribution\n",
    "        pdf = genextreme.pdf(x, shape, loc=loc, scale=scale)\n",
    "        \n",
    "        # Plot histogram and GEV PDF\n",
    "        plt.hist(e, bins=25, density=True, alpha=0.7, color='blue', edgecolor='black', label='Empirical Data')\n",
    "        plt.plot(x, pdf, 'r-', label='GEV Fit')\n",
    "        plt.title('Extreme Values and GEV Fit for '+str(key), fontsize=14, fontweight=\"bold\")\n",
    "        \n",
    "        plt.xlabel('GIC', fontsize=12)\n",
    "        plt.ylabel('Density', fontsize=12)\n",
    "\n",
    "        # Grid and legend\n",
    "        plt.grid(visible=True, linestyle=\"--\", alpha=0.5)\n",
    "        \n",
    "        # Tight layout for better spacing\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"/Users/ryanmc/Documents/Conferences/AGU2024/poster_figures/risk_science/eva_gev.png\", format=\"png\", dpi=300)\n",
    "        \n",
    "        # Show the figure\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Step three: get return periods\n",
    "for sensor_eva, e in extreme_value_fits.items():\n",
    "    if sensor_eva == key:\n",
    "        # Define return periods (in years)\n",
    "        # return_periods = np.array([10, 20, 50, 100])\n",
    "        return_periods = np.array([1,5,10,15,20])\n",
    "        \n",
    "        # Calculate return levels\n",
    "        return_levels = genextreme.isf(1 / return_periods, e[0], loc=e[1], scale=e[2])\n",
    "        \n",
    "        # Display results\n",
    "        for rp, rl in zip(return_periods, return_levels):\n",
    "            print(f\"Return Period for sensor_eva {sensor_eva}: {rp} years, Return Level: {rl:.2f}\")\n",
    "    \n",
    "    \n",
    "        plt.figure()\n",
    "        plt.plot(return_periods, return_levels, marker='o', label='Return Levels')\n",
    "        plt.title('Return Levels vs Return Periods for '+str(sensor_eva))\n",
    "        plt.xlabel('Return Period (years)')\n",
    "        plt.ylabel('Return Level')\n",
    "        plt.xscale('log')  # Log scale for better visualization\n",
    "        \n",
    "        # Grid and legend\n",
    "        plt.grid(visible=True, linestyle=\"--\", alpha=0.5)\n",
    "        \n",
    "        # Tight layout for better spacing\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"/Users/ryanmc/Documents/Conferences/AGU2024/poster_figures/risk_science/return_periods.png\", format=\"png\", dpi=300)\n",
    "        \n",
    "        # Show the figure\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84faed8e-0df6-4dab-a424-edc569f3c9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
