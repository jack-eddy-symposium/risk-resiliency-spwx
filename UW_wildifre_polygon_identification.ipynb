{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57070db8-45ac-48e1-961a-a6f407a553c9",
   "metadata": {},
   "source": [
    "This is a script developed by UW Capstone Student Linzheng Zhang in Spring 2025, specifically developed for the March-April 2023 event\n",
    "\n",
    "Some communication: \n",
    "\n",
    "Ryan: \n",
    "I'm curious if you could easily run your wildfire polygon identification algorithm for the time period March 25-April 5, 2023 (or point me to the relevant code you have and I'll touch it up to analyze that event)? The most usable output would be a geopandas dataframe that has columns: [datetime, geometry (of the identified polygon)]\n",
    "I believe you have been working with the MODIS data, right? It might be good to include the number of data points that contribute to the polygon and some sort of median or average of their 'confidence' so we can know how reliable those data are\n",
    "To be consistent with the other data, 15-minute time resolution would be excellent\n",
    "\n",
    "Linzheng Zhang:\n",
    "Iâ€™ll focus on identifying wildfire polygons for the specified time period and review the results. It appears the output already includes those columns.\n",
    "Yes, this is MODIS data. (It might be helpful to include the number of data points contributing to each polygon, along with a median or average confidence level, to better assess data reliability.) That aligns with my thinking last quarter. I previously believed that a higher number of data points and greater confidence levels would strengthen the identification of true correlations.\n",
    "Thank you for providing the 15-minute time window.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a015828-164f-42c4-967b-d839e2b95e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd552e49-0e84-4766-b983-9d374a7a5af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac35a7f3-a061-4896-9262-159975c1b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the code to calculate and add a new parameter to result_rows representing the total area of the wildfire cluster, taking into account cases where the wildfire is represented by a single point.\n",
    "grouped = gdf_modis_wildfire_mar_apr_2023.groupby(gdf_modis_wildfire_mar_apr_2023['datetime'].dt.floor('H'))\n",
    "result_rows = []\n",
    "for datetime_value, group in grouped:\n",
    "    points = group['geometry'].tolist()\n",
    "    clustered_points = []\n",
    "    # Track visited points\n",
    "    visited = set()\n",
    "    for i, point in enumerate(points):\n",
    "        if i in visited:\n",
    "            continue\n",
    "        # Start a cluster\n",
    "        cluster = [point]\n",
    "        cluster_indices = [i]  # Track indices of points in this cluster\n",
    "        visited.add(i)\n",
    "        for j, other_point in enumerate(points):\n",
    "            if j not in visited and point.distance(other_point) <= 2 :  # and point.distance(other_point) <= .1:\n",
    "                cluster.append(other_point)\n",
    "                cluster_indices.append(j)\n",
    "                visited.add(j)\n",
    "        # Create a polygon from the clustered points\n",
    "        polygon = MultiPoint(cluster).convex_hull\n",
    "        # Calculate aggregate values for the cluster\n",
    "        cluster_data = group.iloc[cluster_indices]\n",
    "        # Calculate total area of the polygon\n",
    "        if polygon.geom_type == 'Polygon':\n",
    "            total_area = polygon.area  # Area of the polygon in square degrees (adjust units if needed)\n",
    "        elif polygon.geom_type == 'Point':\n",
    "            # If a single point, use a default area (e.g., area of a circle with a radius of 0.01 degrees)\n",
    "            default_radius = 0.01\n",
    "            total_area = np.pi * (default_radius ** 2)\n",
    "        else:\n",
    "            total_area = 0  # Handle other geometry types if necessary\n",
    "        # Calculate statistics for numerical attributes\n",
    "        sum_frp = cluster_data['FRP'].sum()\n",
    "        mean_frp = cluster_data['FRP'].mean()\n",
    "        max_frp = cluster_data['FRP'].max()\n",
    "        mean_confidence = cluster_data['CONFIDENCE'].mean()\n",
    "        max_confidence = cluster_data['CONFIDENCE'].max()\n",
    "        # For TYPE, get the most common value (mode)\n",
    "        most_common_type = cluster_data['TYPE'].mode().iloc[0] if not cluster_data['TYPE'].empty else None\n",
    "        # Count points in cluster (fire size indicator)\n",
    "        point_count = len(cluster)\n",
    "        result_rows.append({\n",
    "            'datetime': datetime_value,\n",
    "            'geometry': polygon,\n",
    "            'point_count': point_count,\n",
    "            'total_area': total_area,\n",
    "            'sum_FRP': sum_frp,\n",
    "            'mean_FRP': mean_frp,\n",
    "            'max_FRP': max_frp,\n",
    "            'mean_CONFIDENCE': mean_confidence,\n",
    "            'max_CONFIDENCE': max_confidence,\n",
    "            'TYPE': most_common_type\n",
    "        })\n",
    "# Create a new GeoDataFrame from the result with all the added attributes\n",
    "gdf_modis_wildfire_result = gpd.GeoDataFrame(\n",
    "    result_rows,\n",
    "    columns=['datetime', 'geometry', 'point_count', 'total_area', 'sum_FRP', 'mean_FRP', 'max_FRP',\n",
    "             'mean_CONFIDENCE', 'max_CONFIDENCE', \n",
    "             'TYPE'],\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "gdf_modis_wildfire_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c4f14-ff34-40c5-b113-969e718270cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plus counting the total_area\n",
    "radius = 0.2  # Example radius in degrees (adjust based on your CRS)\n",
    "candidates = []\n",
    "for index_w, row_w in gdf_modis_wildfire_result.iterrows():\n",
    "    # Identify overlap in time with the power grid disturbance\n",
    "    wildfire_datetime = row_w.datetime\n",
    "    filtered_outage_data_gdf = outage_data_gdf[\n",
    "        (outage_data_gdf['outage_start_time'] >= wildfire_datetime - pd.Timedelta(hours=1)) &\n",
    "        (outage_data_gdf['outage_start_time'] <= wildfire_datetime + pd.Timedelta(days=1))\n",
    "    ]\n",
    "    # Identify overlap in space with the power grid disturbance\n",
    "    geom = row_w.geometry\n",
    "    # Check if the geometry is a Point\n",
    "    if geom.geom_type == 'Point':\n",
    "        # Create a buffer (circular area) around the point\n",
    "        buffered_wildfire_area = geom.buffer(radius)\n",
    "        disp_geom = geom.coords[0]\n",
    "    # Check if the geometry is a Polygon\n",
    "    elif geom.geom_type == 'Polygon':\n",
    "        buffered_wildfire_area = geom\n",
    "        disp_geom = geom.exterior.coords[0]\n",
    "    for f in range(len(filtered_outage_data_gdf)):\n",
    "        if buffered_wildfire_area.intersects(filtered_outage_data_gdf['geometry'].iloc[f]):\n",
    "            # Print information about the match\n",
    "            print('candidate at {}! \\n wildfire: \\n \\t {} \\n outage: \\n \\t {} for {}'.format(\n",
    "                wildfire_datetime,\n",
    "                disp_geom,\n",
    "                filtered_outage_data_gdf['outage_start_time'].iloc[f],\n",
    "                filtered_outage_data_gdf['area affected'].iloc[f],\n",
    "            ))\n",
    "            # Save detailed information from both wildfire and outage\n",
    "            candidates.append({\n",
    "                # Original wildfire information\n",
    "                'wildfire_datetime': wildfire_datetime,\n",
    "                'wildfire_geometry': geom,\n",
    "                # total_area\n",
    "                'wildfire_total_area': row_w.total_area,\n",
    "                # New wildfire metrics\n",
    "                'wildfire_point_count': row_w.point_count,  # Size indicator\n",
    "                'wildfire_sum_FRP': row_w.sum_FRP,          # Total fire radiative power\n",
    "                'wildfire_mean_FRP': row_w.mean_FRP,        # Average intensity\n",
    "                'wildfire_max_FRP': row_w.max_FRP,          # Peak intensity\n",
    "                'wildfire_mean_CONFIDENCE': row_w.mean_CONFIDENCE,\n",
    "                'wildfire_max_CONFIDENCE': row_w.max_CONFIDENCE,\n",
    "                'wildfire_TYPE': row_w.TYPE,\n",
    "                # Outage information\n",
    "                'outage_start_time': filtered_outage_data_gdf['outage_start_time'].iloc[f],\n",
    "                'outage_stop_time': filtered_outage_data_gdf['outage_stop_time'].iloc[f],\n",
    "                'customers_affected': filtered_outage_data_gdf['customers_affected'].iloc[f],\n",
    "                'outage_geometry': filtered_outage_data_gdf['geometry'].iloc[f],\n",
    "                'area_affected': filtered_outage_data_gdf['area affected'].iloc[f],\n",
    "            })\n",
    "            break\n",
    "    continue\n",
    "# Convert candidates to a DataFrame for further analysis\n",
    "candidates_df = pd.DataFrame(candidates)\n",
    "candidates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6702f8-a96c-47d8-a876-b17a7f151b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02b960d3-8322-4b2c-ba74-d6fa58d457a0",
   "metadata": {},
   "source": [
    "The following three pieces of data are screened out by me according to your requirements. For this method, I mainly use hours as the condition for grouping related wildfires first. At the same time, point.distance(other_point) <= 2 is set as the distance limit for wildfire points in the cluster. For isolated wildfire points, I manually set a circle with the default radius as the condition for calculating the area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908b2767-9e43-41de-8de9-a1133b4ae920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"img/picture.png\")\n",
    "\n",
    "![title](img/picture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d146c17-20bb-41ef-ad82-c25f4ce61346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
