{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec74d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import random \n",
    "\n",
    "\n",
    "from datetime import date, datetime, timedelta, time\n",
    "\n",
    "from sunpy.net import Fido\n",
    "from sunpy.net import attrs as a\n",
    "from sunpy.timeseries import TimeSeries\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e082abe8",
   "metadata": {},
   "source": [
    "Steps\n",
    "1. Choose event\n",
    "2. Get GIC data and clean\n",
    "3. Get MAG data and clean\n",
    "4. Get solar wind and geo index data\n",
    "5. Integrate based on datetime \n",
    "6. Output integrated data files for GIC and MAG separately\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6537c9e",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae0cd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2406dee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nerc_string_time_reader(df,columnLabel):\n",
    "    '''\n",
    "        df = dataframe with NERC data readings\n",
    "        columnLabel = column label for the time strings  \n",
    "    '''\n",
    "    \n",
    "    dt_list = [datetime.strptime(val, '%m/%d/%Y %I:%M:%S %p') for val in df[columnLabel].values]\n",
    "    \n",
    "    return dt_list\n",
    "\n",
    "\n",
    "def nerc_gic_data_cleaning(dir_location, df_GIC):\n",
    "    '''\n",
    "        Returns a string with Device IDs that indicate bad stations to remove from the DF of GIC observations\n",
    "    '''\n",
    "    \n",
    "    running_bad_station_list = []\n",
    "    \n",
    "    # Remove Stations with error quality reports\n",
    "    for file in glob.glob(os.path.join(dir_location,'gic_monitor_missing_data*')):\n",
    "        file_errors = file\n",
    "#         file_errors = 'gic_monitor_missing_data_data_quality_reports_2015E06.csv'\n",
    "    bad_gic_data = pd.read_csv(file_errors)\n",
    "    print('bad gic stations for this event = \\n{}'.format(list(set(bad_gic_data['Device ID'].values))))\n",
    "\n",
    "    for l in list(set(bad_gic_data['Device ID'].values)):\n",
    "        running_bad_station_list.append(str(l))\n",
    "        \n",
    "    # Remove Stations with low numbers of observations or whose observations are constant\n",
    "    for c in df_GIC.columns.to_list():\n",
    "\n",
    "        nan_mask = ~np.isnan(df_GIC[c])\n",
    "\n",
    "        if df_GIC[c].count() < 2000.:\n",
    "            running_bad_station_list.append(c)\n",
    "        elif ( len(np.unique((df_GIC[c][nan_mask]))) < 10 ): # less than 10 unique data points\n",
    "            print('station {} has < 10 unique data points'.format(c))\n",
    "            running_bad_station_list.append(c)\n",
    "        \n",
    "    \n",
    "    return running_bad_station_list\n",
    "\n",
    "\n",
    "def nerc_gic_data_reshaping(df):\n",
    "    '''\n",
    "        df must have the following columns:\n",
    "            GICDeviceID\n",
    "            SampleDateTime\n",
    "            GICMeasured\n",
    "    '''\n",
    "    list_times = nerc_string_time_reader(df,'SampleDateTime')\n",
    "#     list_times\n",
    "    \n",
    "    df_times = pd.Series(list_times,name='datetimes')\n",
    "    df_new = pd.concat([df,df_times],axis=1)\n",
    "    df_new = df_new.set_index('datetimes')\n",
    "    colName = str(df_new['GICDeviceID'].values[0])\n",
    "    df_new = df_new.rename(columns={\"GICMeasured\": colName})\n",
    "    df_new = df_new.drop(columns=['GICDeviceID','SampleDateTime'])\n",
    "\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current working directory: {0}\".format(cwd))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cead6d20",
   "metadata": {},
   "source": [
    "### Choose event and get files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143bd114",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_no = 8\n",
    "\n",
    "\n",
    "event_list = np.loadtxt('event_list.txt', str)\n",
    "\n",
    "for i in range(len(event_list)):\n",
    "    print('\\t events list item {}:{}'.format(i,event_list[i]))\n",
    "\n",
    "files_dir_gic = 'data/'+event_list[event_no,3]+'/GIC/'\n",
    "\n",
    "\n",
    "print(files_dir_gic) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725b7b6d",
   "metadata": {},
   "source": [
    "### Get GIC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9811c640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of datetimes spanning the event and that will be used as the common index for all time series\n",
    "\n",
    "format = '%Y-%m-%dT%H:%M'\n",
    "\n",
    "event_start = datetime.strptime(event_list[event_no,1], format)\n",
    "event_end = datetime.strptime(event_list[event_no,2], format) + timedelta(days=1)\n",
    "df_event_dates = pd.date_range(event_start,event_end,freq='10s')\n",
    "\n",
    "df_event_dates = df_event_dates.to_pydatetime()\n",
    "df_event_dates = pd.DataFrame(df_event_dates,columns=['datetimes'])\n",
    "# df_event_dates = df_event_dates.index.rename('Datetimes', inplace=True)\n",
    "df_event_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7c44f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop over files in the directory for a given event and create merged DFs for GICs\n",
    "\n",
    "df_GIC = df_event_dates\n",
    "\n",
    "for f in glob.glob(os.path.join(files_dir_gic,'*csv')):#[0:10]:\n",
    "    \n",
    "    # Skip missing data files\n",
    "    if ('missing' in f) | ('monitor' in f) | ('magnetometers' in f):\n",
    "        print('-------> skipping file = {}'.format(f))\n",
    "        continue\n",
    "    print(f)\n",
    "    \n",
    "    # Read and reshape the data\n",
    "    df_loop = pd.read_csv(f)\n",
    "    \n",
    "    df_loop = nerc_gic_data_reshaping(df_loop)\n",
    "            \n",
    "    # Merge into full dataframe\n",
    "    df_GIC = pd.merge(df_GIC, df_loop, on='datetimes',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee255bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f996ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GIC.columns[1:].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d00d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "# fig = plt.figure(figsize=(10,5))\n",
    "fig=go.Figure()\n",
    "\n",
    "for i in range(0,2):\n",
    "    rnd_st = df_GIC.columns.to_list()[random.randint(0,len(df_GIC.columns)-1)]\n",
    "\n",
    "    print('plotting station = {}'.format(rnd_st))\n",
    "#     px.scatter(df_GIC,x='datetimes',y=rnd_st)\n",
    "    fig.add_trace(go.Scatter(x=df_GIC['datetimes'], \n",
    "                             y=df_GIC[rnd_st],\n",
    "                             mode='markers'))\n",
    "    \n",
    "#     plt.scatter(df_GIC['datetimes'].values,df_GIC[rnd_st],label=rnd_st)\n",
    "# plt.grid(True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b43c6e8",
   "metadata": {},
   "source": [
    "### Apply filtering of GIC data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9ad4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_stations = nerc_gic_data_cleaning(files_dir_gic, df_GIC)\n",
    "print(bad_stations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ed352",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Number of stations prior to removal of bad data = {}'.format(df_GIC.shape[1]))\n",
    "df_GIC = df_GIC.copy(True).drop(columns=bad_stations)\n",
    "print('Number of stations after removal of bad data = {}'.format(df_GIC.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854c0c31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "069e5c27",
   "metadata": {},
   "source": [
    "### Align with solar wind and geo indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12007416",
   "metadata": {},
   "outputs": [],
   "source": [
    "sunpy_format = '%Y/%m/%d %H:%M'\n",
    "\n",
    "trange = a.Time(event_start.strftime(sunpy_format), event_end.strftime(sunpy_format))\n",
    "dataset = a.cdaweb.Dataset('OMNI_HRO2_5MIN')\n",
    "result = Fido.search(trange, dataset)\n",
    "\n",
    "downloaded_files = Fido.fetch(result[0])\n",
    "print(downloaded_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46335ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "sw_data = TimeSeries(downloaded_files, concatenate=True)\n",
    "df_sw = sw_data.to_dataframe()\n",
    "df_sw['datetimes'] = df_sw.index\n",
    "\n",
    "print(df_sw.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1609383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the filling values in the solar wind + geomag indices data\n",
    "\n",
    "dict_mag = {9999.990234375: np.nan}\n",
    "dict_vel = {99999.8984375: np.nan}\n",
    "dict_den = {999.989990234375: np.nan}\n",
    "dict_pre = {99.98999786376953: np.nan}\n",
    "dict_ind = {99999: np.nan}\n",
    "\n",
    "df_sw = df_sw.replace({'F': dict_mag})\n",
    "df_sw = df_sw.replace({'BX_GSE': dict_mag})\n",
    "df_sw = df_sw.replace({'BY_GSM': dict_mag})\n",
    "df_sw = df_sw.replace({'BZ_GSM': dict_mag})\n",
    "df_sw = df_sw.replace({'flow_speed': dict_vel})\n",
    "df_sw = df_sw.replace({'proton_density': dict_den})\n",
    "df_sw = df_sw.replace({'Pressure': dict_pre})\n",
    "df_sw = df_sw.replace({'SYM_H': dict_ind})\n",
    "df_sw = df_sw.replace({'AE_INDEX': dict_ind})\n",
    "df_sw = df_sw.replace({'AL_INDEX': dict_ind})\n",
    "df_sw = df_sw.replace({'AU_INDEX': dict_ind})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2ce916",
   "metadata": {},
   "source": [
    "### Merge solar wind, geo indices, and GIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393149e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df_GIC,df_sw,on='datetimes',how='left')\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa51d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4373aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "391718d6",
   "metadata": {},
   "source": [
    "### Visualize as check on process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c29bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ID = '10119'\n",
    "\n",
    "\n",
    "fig, axarr = plt.subplots(8, sharex=True)\n",
    "plt.subplots_adjust(hspace = .001) \n",
    "\n",
    "axarr[0].set_xlim([event_start,event_end])\n",
    "\n",
    "axarr[0].set_ylabel('|B| [nT]')\n",
    "axarr[0].scatter(df_final['datetimes'], df_final['F'], color='black', s=8)\n",
    "\n",
    "axarr[1].set_ylabel('B_GSM [nT]')\n",
    "axarr[1].scatter(df_final['datetimes'], df_final['BX_GSE'], color='tab:blue', s=8)\n",
    "axarr[1].scatter(df_final['datetimes'], df_final['BY_GSM'], color='tab:orange', s=8)\n",
    "axarr[1].scatter(df_final['datetimes'], df_final['BZ_GSM'], color='tab:green', s=8)\n",
    "\n",
    "axarr[2].set_ylabel('V [km/s]')\n",
    "axarr[2].scatter(df_final['datetimes'], df_final['flow_speed'], color='black', s=8)\n",
    "\n",
    "axarr[3].set_ylabel('Np [#/cc]')\n",
    "axarr[3].scatter(df_final['datetimes'], df_final['proton_density'], color='black', s=8)\n",
    "\n",
    "axarr[4].set_ylabel('P [nPa]')\n",
    "axarr[4].scatter(df_final['datetimes'], df_final['Pressure'], color='black', s=8)\n",
    "\n",
    "axarr[5].set_ylabel('SYM-H [nT]')\n",
    "axarr[5].scatter(df_final['datetimes'], df_final['SYM_H'], color='black', s=8)\n",
    "\n",
    "axarr[6].set_ylabel('AE [nT]')\n",
    "axarr[6].scatter(df_final['datetimes'], df_final['AE_INDEX'], color='black', s=8)\n",
    "\n",
    "axarr[7].set_ylabel('GIC')\n",
    "axarr[7].scatter(df_final['datetimes'], df_final[plot_ID], color='black', lw=0.8)\n",
    "\n",
    "axarr[7].xaxis.set_major_locator(mdates.HourLocator([0,6,12,18]))\n",
    "axarr[7].xaxis.set_major_formatter(mdates.DateFormatter('%H:00'))\n",
    "axarr[7].tick_params(axis='x', which='major')\n",
    "\n",
    "xaxis_copy = axarr[7].secondary_xaxis('bottom')\n",
    "xaxis_copy.xaxis.set_major_locator(mdates.DayLocator(interval=1))\n",
    "xaxis_copy.xaxis.set_major_formatter(mdates.DateFormatter('%n %Y-%m-%d'))\n",
    "xaxis_copy.tick_params(axis='x', which='major')\n",
    "\n",
    "fig.set_size_inches(12,10)\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdd14fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'/Users/ryanmc/Documents/Conferences/Jack_Eddy_Symposium_2022/data/integrated_data_'+event_list[event_no][3]+'.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad9bc30",
   "metadata": {},
   "source": [
    "### Save the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de2707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('/Users/ryanmc/Documents/Conferences/Jack_Eddy_Symposium_2022/dev/integrated_data/integrated_data_'+event_list[event_no][3]+'.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f9d2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791eec7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a854ed37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a2604f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
